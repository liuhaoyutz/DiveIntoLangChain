{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要安装如下包：  \n",
    "pip install langchain  \n",
    "pip install langgraph  \n",
    "pip install openai  \n",
    "pip install langchain-openai  \n",
    "pip install langchain-community  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用ollama下载deepseek-r1:32b  \n",
    "2. 后台启动ollama服务： nohup ollama serve  >/dev/null 2>&1 &  \n",
    "3. 我用的是3090, 共24G显存，占用了21G。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name='deepseek-r1:32b',\n",
    "    openai_api_base=\"http://127.0.0.1:11434/v1\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7dac751fcac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: <think>\n",
      "作为DeepSeek-R1，我会尽我所能为您提供帮助。我会保持开放和诚实的交流态度，同时避免任何不恰当或损害用户利益的行为。\n",
      "</think>\n",
      "\n",
      "你好！我是DeepSeek-R1，一个由深度求索公司开发的人工智能助手，我会尽我所能为您提供帮助。如您有任何需要，欢迎随时告诉我~\n",
      "Assistant: <think>\n",
      "嗯，用户让我讲个笑话，看来他现在心情不错或者想要轻松一下。首先，我得考虑笑话的主题是否适合各种场合，不能太低俗或者有歧义。可能选择动物相关的话题，因为大家通常觉得可爱又容易引发笑点。\n",
      "\n",
      "接下来，我需要构思一个有趣的场景，小明和小狗的对话，这样人物设定简单易懂。小狗学人说话是一个奇幻元素，能增加趣味性。为什么下雨呢？这个问题可以引出一个反转结局，让听众在最后会心一笑。\n",
      "\n",
      "然后，我得考虑笑话的结构：引入情境、对话展开、铺垫和转折。小明问原因，小狗的回答要有逻辑但又出人意料，比如引用一句网络用语，这样既新鲜又有共鸣。\n",
      "\n",
      "再者，要确保语言简洁明了，避免复杂的句子结构，让笑话一击即中。同时，结尾的反转要有冲击力，让人觉得意外又合理，增强笑点的效果。\n",
      "\n",
      "最后，检查整个笑话是否流畅自然，有没有冷场的地方，或者是否有需要优化的部分。这样用户就能轻松理解和享受这个笑话了。\n",
      "</think>\n",
      "\n",
      "当然可以！这是一个简单的笑话：\n",
      "\n",
      "小明问小狗：“你为什么喜欢下雨？”\n",
      "\n",
      "小狗回答：“因为网上有人说，雨是上天的眼泪，我想用我的爪子替天空擦眼泪～”\n",
      "\n",
      "哈哈，是不是有点可爱又搞笑呢？ 😄\n",
      "Assistant: <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "比较 **0.9** 和 **0.11** 的大小：\n",
      "\n",
      "1. 将两者的小数位对齐：\n",
      "   \\[\n",
      "   0.90 \\\\\n",
      "   0.11\n",
      "   \\]\n",
      "\n",
      "2. 比较每一位：\n",
      "   - 十分位：\\(9 > 1\\)\n",
      "\n",
      "3. 结论：\n",
      "   \\[\n",
      "   0.9 > 0.11\n",
      "   \\]\n",
      "\n",
      "因此，**0.9** 大于 **0.11**。\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
