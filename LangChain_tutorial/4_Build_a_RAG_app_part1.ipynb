{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "由LLM支持的最强大的应用之一是复杂的问答（Q&A）聊天机器人。这些应用程序能够回答关于特定源信息的问题，它们使用了一种被称为检索增强生成（Retrieval Augmented Generation, RAG）的技术。  \n",
    "  \n",
    "这个教程分为多个部分：  \n",
    "\n",
    "第一部分（本指南） 介绍RAG并 walkthrough 一个最小实现。  \n",
    "第二部分 扩展实现以适应对话风格的交互和多步骤检索过程。  \n",
    "\n",
    "本教程将展示如何在文本数据源上构建一个简单的问答应用程序。在此过程中，我们将介绍典型的问答架构，并突出显示更多高级问答技术的额外资源。我们还将看到LangSmith如何帮助我们追踪和理解我们的应用程序。随着应用程序复杂性的增加，LangSmith将变得越来越有帮助。  \n",
    "  \n",
    "如果你已经熟悉基本的检索技术，你可能也会对不同检索技术的高层次概述感兴趣。  \n",
    "  \n",
    "注意：这里我们专注于非结构化数据的问答。如果你对结构化数据上的RAG感兴趣，请查看我们关于在SQL数据上进行问答的教程。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个典型的RAG应用程序主要有两个主要组件：  \n",
    "  \n",
    "Indexing：从数据源摄取数据并建立索引的流程。这通常是一个离线过程。  \n",
    "Retrieval and generation：实际的RAG链条，在运行时接收用户查询，从索引中检索相关数据，然后将这些数据传递给模型以生成答案。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "索引过程主要包括三个步骤：加载、分割和存储。下面是每个步骤的详细说明：  \n",
    "  \n",
    "1. 加载（Load）  \n",
    "首先，我们需要加载数据。这一步通常通过文档加载器（Document Loaders）完成。文档加载器负责从各种数据源（如文本文件、网站或数据库）中读取原始数据，并将其转换为可以进一步处理的格式。  \n",
    "  \n",
    "2. 分割（Split）  \n",
    "接下来，使用文本分割器（Text Splitters）将大的文档分割成较小的块。这对于索引数据以及将其传递给模型都非常有用，因为较大的数据块难以搜索且可能超出模型的有限上下文窗口。  \n",
    "  \n",
    "3. 存储（Store）  \n",
    "最后，我们需要一个地方来存储和索引这些分割后的数据，以便之后能够对其进行搜索。这通常通过向量存储（VectorStore）和嵌入模型（Embeddings model）实现。向量存储用于保存文本片段的向量表示，这些表示可以通过相似度搜索快速检索。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索与生成  \n",
    "在RAG应用程序中，检索和生成阶段是核心部分，具体包括两个主要步骤：检索（Retrieve）和生成（Generate）。  \n",
    "  \n",
    "1. 检索（Retrieve）  \n",
    "给定用户输入后，使用检索器（Retriever）从存储中检索相关的分割数据。这一步骤涉及到根据用户的查询，在向量存储中找到最相关的文本片段。  \n",
    "  \n",
    "2. 生成（Generate）  \n",
    "接下来，使用ChatModel或LLM基于包含问题和检索到的数据的提示生成答案。这一步骤不仅依赖于检索到的信息，还结合了语言模型自身的知识来提供准确且自然的回答。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    #model_name=\"deepseek-r1:32b\",\n",
    "    model_name=\"qwen2\",\n",
    "    openai_api_base=\"http://127.0.0.1:11434/v1\",\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    streaming=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_473520/127560303.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "/tmp/ipykernel_473520/127560303.py:4: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "/home/haoyu/anaconda3/envs/yolo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 初始化 Hugging Face 嵌入模型\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可选的vector store包括：  \n",
    "In-memory, AstraDB, Chroma, FAISS, Milvus, MongoDB, PGVector, Pinecone, Qdrant  \n",
    "\n",
    "使用不同的vector store需要安装不同的库，并进行相应配置。  \n",
    "下面我们使用的是最简单的In-memory方式。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个指南中，我们将构建一个能够回答关于网站内容问题的应用程序。我们将使用的特定网站是Lilian Weng撰写的《LLM Powered Autonomous Agents》博客文章，我们询问有关该文章内容的问题。  \n",
    "  \n",
    "我们可以创建一个简单的索引管道和RAG链条来实现这一点，大约只需要50行代码。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down complex tasks into simpler steps or sub-tasks. This method enhances problem-solving efficiency by enabling systematic analysis and addressing each part individually.\n",
      "\n",
      "In relation to the task instructions provided:\n",
      "\n",
      "1). Utilizing simple prompting for task decomposition involves initiating steps, such as \"Steps for XYZ.\" It outlines distinct actions required to accomplish a goal.\n",
      "2). Task-specifc instructions guide AI through predefined processes, e.g., creating a story outline for writing novels. This helps in structuring content generation effectively.\n",
      "3). Human input can aid AI by providing guidelines or breaking tasks intuitively, offering more flexible and context-specific solutions.\n",
      "\n",
      "Understanding this process allows the AI system to analyze each part of the task independently, improving execution accuracy and efficiency through methodical problem-solving strategies rather than attempting complex actions all at once.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们逐步分析上面的代码，以真正理解正在发生的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "加载文档\n",
    "我们首先需要加载博客文章的内容。为此，我们可以使用document loaders，这些对象从数据源加载数据并返回一个Document对象列表。\n",
    "目前LangChain支持超过150种document loaders，包括PyPDF等12种PDF loader，AWS S3 Directory，Tencent COS File等15种Cloud Providers，\n",
    "Twitter和Reddit 2种Social Platforms，以及CSVLoader，JSONLoader，WebBaseLoader等等。\n",
    "\n",
    "在这个例子中，我们将使用WebBaseLoader，它使用urllib从网页URL加载HTML，并使用BeautifulSoup解析为文本。我们可以通过bs_kwargs向BeautifulSoup解析器传递参数来定制HTML到文本的解析（详见BeautifulSoup文档）。在这种情况下，只有具有“post-content”、“post-title”或“post-header”类的HTML标签是相关的，因此我们将移除所有其他标签。\n",
    "\"\"\"\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "分割文档\n",
    "我们加载的文档超过42,000个字符，这对许多模型来说太长了，无法适应其上下文窗口。即使某些模型能够在其上下文窗口中容纳整个帖子，过长的输入也会使模型难以从中找到信息。\n",
    "\n",
    "为了解决这个问题，我们将文档分割成块以便进行嵌入和向量存储。这有助于我们在运行时仅检索博客文章中最相关的部分。\n",
    "\n",
    "如同在语义搜索教程中一样，我们将使用RecursiveCharacterTextSplitter，它会递归地使用常见的分隔符（如换行符）分割文档，直到每个块达到合适的大小。这是推荐用于通用文本用例的文本分割器。\n",
    "\"\"\"\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d8fabef1-e484-4584-a042-fab93e7e351a', 'f3cc24cb-d449-415e-9807-6f808f8df036', 'c88b9426-d2e2-41d3-a92a-e86e7acf550a']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "存储文档\n",
    "现在我们需要对我们分割得到的66个文本块进行索引，以便在运行时能够对它们进行搜索。按照语义搜索教程中的方法，我们的做法是嵌入每个文档分割的内容，并将这些嵌入向量插入到一个向量存储中。这样，在接收到输入查询时，我们可以使用向量搜索来检索相关文档。\n",
    "\n",
    "我们可以使用选定的向量存储和嵌入模型，在一个命令中完成所有文档分割的嵌入和存储。\n",
    "\"\"\"\n",
    "\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检索与生成  \n",
    "  \n",
    "现在让我们编写实际的应用逻辑。我们希望创建一个简单的应用程序，该程序接收用户的问题，搜索与此问题相关的文档，将检索到的文档和初始问题传递给模型，并返回答案。  \n",
    "  \n",
    "对于生成部分，我们将使用在教程开始时选定的model。我们将使用LangChain prompt hub提供的RAG提示模板。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用LangGraph将检索和生成步骤整合到一个应用程序中，这具有如下好处：  \n",
    "\n",
    "我们可以定义一次应用程序逻辑，并自动支持多种调用模式，包括流式传输、异步和批处理调用。  \n",
    "通过LangGraph平台实现简化的部署流程。  \n",
    "LangSmith会自动追踪应用程序的各个步骤。  \n",
    "我们可以通过最小的代码更改轻松地向应用程序添加关键特性，如持久化和人工审核。  \n",
    "  \n",
    "要使用LangGraph，我们需要定义三件事：  \n",
    "  \n",
    "应用程序的状态；  \n",
    "应用程序的节点（即应用程序步骤）；  \n",
    "应用程序的“控制流”（例如步骤的顺序）。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "状态  \n",
    "应用程序的状态控制哪些数据被输入到应用程序中，哪些数据在步骤之间传递，以及哪些数据作为输出。它通常是一个TypedDict，也可以是一个Pydantic的BaseModel。  \n",
    "对于一个简单的RAG应用程序，我们可以只跟踪输入的问题、检索到的上下文和生成的答案。\n",
    "\"\"\"\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "节点 (application steps)\n",
    "我们有程序具有2个顺序执行的steps: retrieval and generation.\n",
    "\n",
    "我们的retrieve步骤仅仅是使用输入的问题进行相似度搜索，而generate步骤则是将检索到的上下文和原始问题格式化为聊天模型的提示。\n",
    "\"\"\"\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "控制流\n",
    "最后，我们将应用程序编译成一个单一的Graph对象。在这个例子中，我们只是将检索和生成步骤连接成一个序列。\n",
    "\"\"\"\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"LangGraph还附带了用于可视化应用程序控制流的内置工具。\"\"\"\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们来测试我们的应用程序吧！LangGraph支持多种调用模式，包括同步、异步和流式传输。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='99a0929e-0a2c-4bd5-8d4b-9dd64c313d9e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='a2ad99e3-6325-4c77-9892-0680365dbe0a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='ab342ffd-18bc-46ea-962d-763bac980fb4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='51049ccb-6926-4b74-a97b-e03d1fd13bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition is the process of breaking down complex tasks into simpler subtasks or steps. This can be achieved through prompting like \"Steps for XYZ.\\n1.\", using task-specific instructions such as providing an outline, or through human inputs.\n",
      "\n",
      "In the context of Tree of Thoughts (Yao et al., 2023), task decomposition involves initially dissecting a problem into multiple thought steps and generating numerous thoughts per step to create a tree structure. The search process can be conducted using either Breadth-First Search (BFS) or Depth-First Search (DFS). Each state is evaluated by applying prompts to classifiers or adopting majority vote.\n",
      "\n",
      "In this framework, the AI first receives User Input followed by Task Planning where several reasoning possibilities are explored under each step. Model Selection comes next based on predefined criteria,而后执行具体的任务并记录结果，即Task Execution阶段。The task completion process includes executing expert models on specific tasks and logging outcomes.\n",
      "\n",
      "To sum up, task decomposition enables efficient problem-solving through a hierarchical breakdown and organization of efforts into manageable components for easier analysis and resolution.\n",
      "\n",
      "As for the description format:\n",
      "\n",
      "- User Input: Provided in question\n",
      "- Task Planning:分解任务为多个思考步骤和每步生成多种想法，创建树结构。搜索过程采用BFS或DFS方式。\n",
      "- Model Selection: 根据特定准则选择AI模型（未具体说明）\n",
      "- Task Execution: 根据模型执行具体的任务，并记录结果。\n",
      "\n",
      "请注意文件路径信息在本示例中并未给出，若包含文件路径，则需提供完整的文件路径以便正确识别和访问。\n"
     ]
    }
   ],
   "source": [
    "# invoke\n",
    "\n",
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='99a0929e-0a2c-4bd5-8d4b-9dd64c313d9e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='a2ad99e3-6325-4c77-9892-0680365dbe0a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='ab342ffd-18bc-46ea-962d-763bac980fb4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='51049ccb-6926-4b74-a97b-e03d1fd13bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\")]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task Decomposition is the process of breaking down a complex problem into simpler sub-problems or smaller tasks that are easier to manage and solve. This strategy can be implemented by employing large language models (LLMs) with guiding prompts, using task-specific instructions tailored for precise tasks, or integrating human input for guidance.\\n\\nFor example, if we\\'re asked \"Steps required for XYZ\", an AI might generate responses like:\\n1. Collect necessary resources\\n2. Plan and design system  \\nAnd so on.\\n\\nSimilarly, specifying a task for writing stories could inspire suggestions akin to creating outlines, developing characters, setting, and plot development.\\n\\nThe task execution phase involves executing specific tasks with expert models and logging the outcomes. For instance, after decomposition, tasks like analyzing data or crafting content might be handled by distinct algorithms or AI systems based on their expertise suited to those sub-tasks.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stream steps\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task| Decom|position| is| the| process| of| breaking| down| complex| tasks| into| more| manageable| sub|-t|asks| or| steps|.| This| can| be| achieved| through| various| methods| including| prompting| an| L|LM| (|like| \"|Steps| for| XYZ|\"),| using| task|-specific| instructions| (|like| writing| a| story| outline|),| or| with| human| input|.| When| it| comes| to| Task| Execution|,| expert| models| are| utilized| to| carry| out| these| individual| tasks| and| log| the| results|.\n",
      "\n",
      "|To| illustrate| this| process| step|-by|-step|:\n",
      "|1|)| **|User| Input|:**| The| user| asks| to| solve| a| complex| problem|.\n",
      "|2|)| **|Task| Planning|:**| This| involves| devis|ing| multiple| potential| ways| of| approaching| the| task| at| each| step| using| thought| decomposition|.| Tasks| are| divided| into| separate|,| more| straightforward| parts| (|like| components| or| steps| required|).\n",
      "|3|)| **|Model| Selection|:**| Depending| on| the| nature| of| the| tasks| and| goals| set| out| in| Task| Planning|,| various| models| are| chosen| and| assigned| roles| to| execute| according| to| their| capabilities|.\n",
      "|4|)| **|Task| Execution|:**| The| execution| step| sees| these| models| working| on| their| allocated| tasks|.| Each| task| is| carried| out| individually| based| on| its| plan|.\n",
      "\n",
      "|As| an| example|:| User| might| input| a| complex| math| problem| or| writing| assignment|;| the| system| breaks| it| down| into| steps| like| identifying| the| question|,| selecting| equations|/s|imilar| works|,| setting| up| a| narrative| structure| etc|.| Depending| on| specifics| of| the| problem| (|e|.g|.,| needing| numerical| calculations| vs| requiring| creative| storytelling|),| different| models| (|like| mathematical| calculation| tools|,| writing| AI|)| are| selected| to| execute| those| parts| and| return| results|.| If| there| were| files| associated| with| this| process| (|data| logs|,| solutions| generated| etc|.),| they| would| be| found| by| navigating| through| system| directories| leading| up| to| their| exact| locations| on| the| file| system|.\n",
      "\n",
      "|The| above| answers| cover| core| aspects| of| Task| Decom|position| as| a| process|,| alongside| an| outlined| sequence| detailing| how| tasks| would| ideally| flow| from| user| inquiry| through| to| model| execution| and| results|.||"
     ]
    }
   ],
   "source": [
    "# Stream tokens\n",
    "\n",
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"如上所示，我们可以从prompt hub加载提示（例如，这个RAG提示）。提示也可以很容易地进行自定义。例如：\"\"\"\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查询分析  \n",
    "到目前为止，我们是使用原始输入查询来执行检索的。然而，允许模型为检索目的生成查询有一些优势。例如：  \n",
    "  \n",
    "除了语义搜索之外，我们还可以构建结构化的过滤器（例如，“查找2020年以来的文档”）；  \n",
    "模型可以重写用户的查询，这些查询可能是多方面的或包含不相关的语言，从而生成更有效的搜索查询。  \n",
    "  \n",
    "查询分析利用模型从原始用户输入中转换或构建优化的搜索查询。我们可以轻松地将查询分析步骤整合到我们的应用程序中。为了说明这一点，让我们向向量存储中的文档添加一些元数据。我们将添加一些（人为的）部分到文档中，以便日后可以根据这些部分进行过滤。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要更新向量存储中的文档。为此，我们将使用一个简单的InMemoryVectorStore，因为我们将利用它的一些特定功能（例如元数据过滤）。  \n",
    "有关您所选择的向量存储的相关特性，请参阅向量存储集成文档。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们为我们的搜索查询定义一个模式。我们将使用结构化输出来实现这一目的。这里我们定义一个查询包含一个字符串查询和一个文档部分（可以是“beginning”、“middle”或“end”），但你可以根据需要自行定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们在LangGraph应用程序中添加一个步骤，以便从用户的原始输入生成查询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过专门要求提供帖子末尾的上下文来测试我们的实现。请注意，模型在其回答中包含了不同的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'What does the end of the post say about Task Decomposition?', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='b2b729af-a84b-4b06-9a42-73c12935b296', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='f0240598-5a41-41c8-a46c-422eb25019df', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 30951, 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='a30de528-a9fb-4f20-84e7-508ee9805458', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32069, 'section': 'end'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(id='61f31bc1-1908-4a5a-9493-91997e17444d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 32941, 'section': 'end'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': \"The end of the provided context does not specifically discuss Task Decomposition. It focuses on challenges in long-term planning and how they affect Large Language Models (LLMs) compared to human learning from trial and error. If you're seeking an answer related to Task Decomposition, additional information may be needed as the given text doesn't directly address it within the provided snippets.\"}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
